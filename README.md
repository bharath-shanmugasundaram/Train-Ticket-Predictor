```markdown
# ğŸš† Train Ticket Booking Prediction â€” Deep Neural Network (NumPy From Scratch)

This project implements a **5-layer deep neural network** (built completely from scratch using NumPy) to predict whether a **train ticket booking** will be **successful or not**, based on various features such as day of week, booking time, train popularity, season, travel class, and booking type.

It demonstrates **manual deep learning implementation**, including feature preprocessing, multi-layer forward propagation, backpropagation, vectorized gradient descent, batching (partially implemented), and model evaluation â€” all **without using TensorFlow, Keras, or PyTorch**.

---

## ğŸ“Œ Project Highlights

- ğŸ”„ Converts all categorical features into numerical form using custom mapping  
- ğŸ¤– Implements a **5-layer feedforward neural network**  
- ğŸ§® Uses **sigmoid activation** for all layers  
- ğŸ§  Fully manual **forward + backward propagation**  
- ğŸ¯ Binary prediction output (0 or 1)  
- ğŸ“‰ Cost tracking over epochs  
- ğŸ“Š Loss curve visualization using Seaborn  
- ğŸ§ª Final model accuracy computed on a separate test dataset  

---

# ğŸ§© Dataset: `train_ticket_booking_dataset_50000.csv`

The dataset contains 50,000+ booking records. Some of the key features:

| Feature | Description |
|--------|-------------|
| `Day_of_Week` | Day the booking was made |
| `Time_of_Booking` | Morning / Afternoon / Evening / Night |
| `Train_Popularity` | Low / Medium / High |
| `Season` | Normal / Holiday / Festival |
| `Travel_Class` | Sleeper / 3AC / 2AC / 1AC |
| `Booking_Type` | Tatkal / Normal |
| `Booking_Status` | Target (0 = Fail, 1 = Success) |

---

## ğŸ§® Data Preprocessing

Categorical values are mapped numerically:

### **Day of Week**
```

Mon â†’ 2
Tue â†’ 3
Wed â†’ 4
Thu â†’ 5
Fri â†’ 6
Sat â†’ 7
Sun â†’ 1

```

### **Time of Booking**
```

Morning â†’ 1
Afternoon â†’ 2
Evening â†’ 3
Night â†’ 4

```

### **Train Popularity**
```

Low â†’ 1
Medium â†’ 2
High â†’ 3

```

### **Season**
```

Normal â†’ 1
Holiday â†’ 2
Festival â†’ 3

```

### **Travel Class**
```

Sleeper â†’ 1
3AC â†’ 2
2AC â†’ 3
1AC â†’ 4

```

### **Booking Type**
```

Tatkal â†’ 1
Normal â†’ 2

```

The dataset is then split into:

- **Training set:** first 50,000 rows  
- **Test set:** exported as `Test_dataset.csv`

---

# ğŸ§  Neural Network Architecture

This model uses **5 fully-connected (dense) layers**:

| Layer | Size | Activation |
|-------|-------|------------|
| Input Layer | 13 features | â€” |
| Hidden Layer 1 | 13 neurons | Sigmoid |
| Hidden Layer 2 | 10 neurons | Sigmoid |
| Hidden Layer 3 | 7 neurons | Sigmoid |
| Hidden Layer 4 | 3 neurons | Sigmoid |
| Output Layer | 1 neuron | Sigmoid |

---

# ğŸ”¢ Forward Propagation Flow

```

X â†’ W1 â†’ A1 â†’ W2 â†’ A2 â†’ W3 â†’ A3 â†’ W4 â†’ A4 â†’ W5 â†’ A5 â†’ Prediction

```

Where:

- `Z = WÂ·X + b`
- `A = sigmoid(Z)`

---

# ğŸ”„ Backpropagation

Gradients for all layers are manually computed:

- `dW5, db5`
- `dW4, db4`
- `dW3, db3`
- `dW2, db2`
- `dW1, db1`

Updating rule:

```

W -= learning_rate * dW
b -= learning_rate * db

````

---

# âš™ï¸ Training Setup

| Parameter | Value |
|-----------|-------|
| Epochs | 10,000 |
| Batch Size | 64 (partial use) |
| Learning Rate | 0.1 |
| Loss Function | Binary Cross Entropy |
| Activation | Sigmoid (all layers) |

Loss is printed every epoch and stored for graphing.

---

## ğŸ“‰ Loss Curve

Plotted using:

```python
sns.lineplot(cost)
````

This visualizes model convergence.

---

# ğŸ§ª Prediction Function

The prediction pipeline:

```python
def predict(X):
    Run forward propagation through all 5 layers
    If output >= 0.5 â†’ Predict 1
    Else â†’ Predict 0
```

---

# ğŸ¯ Model Accuracy

The final accuracy is computed over **all rows in the test set**:

```python
Accuracy : XX.XX%
```

(Your output will vary depending on initialization and data.)

---

# ğŸ“¦ Requirements

Install dependencies:

```bash
pip install numpy pandas seaborn
```

---

# â–¶ï¸ Running the Model

Simply execute:

```bash
python train_model.py
```

Or run all cells in your Jupyter notebook / VSCode environment.

---

# ğŸ§  What You Learn From This Project

* How to preprocess categorical data manually
* How to build a deep neural network *from scratch*
* How forward/backpropagation works internally
* How to implement multi-layer gradient descent in NumPy
* How to evaluate and visualize model performance

---

# ğŸ‘¨â€ğŸ’» Author

**Bharath**
Machine Learning Engineer
Exploring how deep learning works from first principles.

---

If you want, I can also generate:

âœ… Architecture diagram
âœ… Project folder structure
âœ… Model explanation in mathematical format
âœ… Code optimization + refactoring

Just tell me!
